{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcff84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "722d4d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:47:09.198 [Thread-3] INFO  __main__ - Log de ejemplo guardado en archivo y consola.\n"
     ]
    }
   ],
   "source": [
    "#built spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Spark\")\n",
    "    .config(\"spark.driver.extraJavaOptions\", r'-Dlog4j.configurationFile=file:/home/illidan/proyecto_desde0/ETL/log4j.properties')\\\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "logger = spark._jvm.org.apache.log4j.LogManager.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "logger.info(\"Log de ejemplo guardado en archivo y consola.\")\n",
    "\n",
    "errores_detectados = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77cc531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    #geting file path into a dictionary\n",
    "    with open(\"/home/illidan/proyecto_desde0/Config_file/Config.Yaml\", \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "except Exception as error:\n",
    "    logger.error(\"Error ruta .yaml:\" + str(error))\n",
    "    errores_detectados.append(str(e))\n",
    "    \n",
    "#search for the path of the files\n",
    "path_vuelos = config[\"path\"][\"path_vuelos\"]\n",
    "Path_aerolineas = config[\"path\"][\"Path_aerolineas\"]\n",
    "path_aeropuertos = config[\"path\"][\"path_aeropuertos\"]\n",
    "#archivos parquet\n",
    "path_df_flights = config[\"Parquet_file\"][\"df_flights\"]\n",
    "path_df_airline = config[\"Parquet_file\"][\"df_airline\"]\n",
    "path_df_airports = config[\"Parquet_file\"][\"df_airports\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a8bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:47:09.263 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.InMemoryFileIndex - It took 2 ms to list leaf files for 1 paths.\n",
      "15:47:09.272 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.InMemoryFileIndex - It took 1 ms to list leaf files for 1 paths.\n",
      "15:47:09.455 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: \n",
      "15:47:09.456 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: (length(trim(value#211, None)) > 0)\n",
      "15:47:09.479 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_18 stored as values in memory (estimated size 199.0 KiB, free 432.7 MiB)\n",
      "15:47:09.492 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.6 MiB)\n",
      "15:47:09.493 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_18_piece0 in memory on 172.23.57.81:36925 (size: 34.1 KiB, free: 434.0 MiB)\n",
      "15:47:09.493 [Thread-3] INFO  org.apache.spark.SparkContext - Created broadcast 18 from csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:09.494 [Thread-3] INFO  org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 74575111 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "15:47:09.514 [Thread-3] INFO  org.apache.spark.SparkContext - Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:09.515 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 9 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "15:47:09.516 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0)\n",
      "15:47:09.516 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()\n",
      "15:47:09.518 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()\n",
      "15:47:09.519 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[42] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "15:47:09.522 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_19 stored as values in memory (estimated size 13.5 KiB, free 432.6 MiB)\n",
      "15:47:09.525 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 432.6 MiB)\n",
      "15:47:09.526 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_19_piece0 in memory on 172.23.57.81:36925 (size: 6.4 KiB, free: 434.0 MiB)\n",
      "15:47:09.527 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 19 from broadcast at DAGScheduler.scala:1585\n",
      "15:47:09.528 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[42] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "15:47:09.528 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 1 tasks resource profile 0\n",
      "15:47:09.529 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 23) (172.23.57.81, executor driver, partition 0, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:09.532 [Executor task launch worker for task 0.0 in stage 9.0 (TID 23)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 23)\n",
      "15:47:09.538 [Executor task launch worker for task 0.0 in stage 9.0 (TID 23)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 0-74575111, partition values: [empty row]\n",
      "15:47:09.546 [Executor task launch worker for task 0.0 in stage 9.0 (TID 23)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 23). 1861 bytes result sent to driver\n",
      "15:47:09.547 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 23) in 18 ms on 172.23.57.81 (executor driver) (1/1)\n",
      "15:47:09.548 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "15:47:09.549 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 9 (csv at NativeMethodAccessorImpl.java:0) finished in 0.028 s\n",
      "15:47:09.549 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "15:47:09.549 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 9: Stage finished\n",
      "15:47:09.550 [Thread-3] INFO  org.apache.spark.scheduler.DAGScheduler - Job 9 finished: csv at NativeMethodAccessorImpl.java:0, took 0.035236 s\n",
      "15:47:09.565 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: \n",
      "15:47:09.565 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: \n",
      "15:47:09.571 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_20 stored as values in memory (estimated size 199.0 KiB, free 432.4 MiB)\n",
      "15:47:09.581 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.4 MiB)\n",
      "15:47:09.589 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_20_piece0 in memory on 172.23.57.81:36925 (size: 34.1 KiB, free: 434.0 MiB)\n",
      "15:47:09.591 [Thread-3] INFO  org.apache.spark.SparkContext - Created broadcast 20 from csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:09.592 [Thread-3] INFO  org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 74575111 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "15:47:09.622 [Thread-3] INFO  org.apache.spark.SparkContext - Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:09.623 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 10 (csv at NativeMethodAccessorImpl.java:0) with 8 output partitions\n",
      "15:47:09.623 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 10 (csv at NativeMethodAccessorImpl.java:0)\n",
      "15:47:09.623 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()\n",
      "15:47:09.627 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()\n",
      "15:47:09.628 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (MapPartitionsRDD[48] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "15:47:09.638 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_21 stored as values in memory (estimated size 27.4 KiB, free 432.4 MiB)\n",
      "15:47:09.640 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.4 MiB)\n",
      "15:47:09.641 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_21_piece0 in memory on 172.23.57.81:36925 (size: 13.0 KiB, free: 434.0 MiB)\n",
      "15:47:09.641 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1585\n",
      "15:47:09.642 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 8 missing tasks from ResultStage 10 (MapPartitionsRDD[48] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))\n",
      "15:47:09.642 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 8 tasks resource profile 0\n",
      "15:47:09.644 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 24) (172.23.57.81, executor driver, partition 0, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:09.644 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 10.0 (TID 25) (172.23.57.81, executor driver, partition 1, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:09.645 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 10.0 (TID 26) (172.23.57.81, executor driver, partition 2, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:09.645 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 10.0 (TID 27) (172.23.57.81, executor driver, partition 3, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:09.645 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 10.0 (TID 28) (172.23.57.81, executor driver, partition 4, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:09.646 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 10.0 (TID 29) (172.23.57.81, executor driver, partition 5, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:09.646 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 10.0 (TID 30) (172.23.57.81, executor driver, partition 6, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:09.647 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 10.0 (TID 31) (172.23.57.81, executor driver, partition 7, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:09.647 [Executor task launch worker for task 0.0 in stage 10.0 (TID 24)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 24)\n",
      "15:47:09.648 [Executor task launch worker for task 1.0 in stage 10.0 (TID 25)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 10.0 (TID 25)\n",
      "15:47:09.653 [Executor task launch worker for task 2.0 in stage 10.0 (TID 26)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 10.0 (TID 26)\n",
      "15:47:09.654 [Executor task launch worker for task 3.0 in stage 10.0 (TID 27)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 10.0 (TID 27)\n",
      "15:47:09.654 [Executor task launch worker for task 4.0 in stage 10.0 (TID 28)] INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 10.0 (TID 28)\n",
      "15:47:09.656 [Executor task launch worker for task 6.0 in stage 10.0 (TID 30)] INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 10.0 (TID 30)\n",
      "15:47:09.655 [Executor task launch worker for task 5.0 in stage 10.0 (TID 29)] INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 10.0 (TID 29)\n",
      "15:47:09.669 [Executor task launch worker for task 1.0 in stage 10.0 (TID 25)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 74575111-149150222, partition values: [empty row]\n",
      "15:47:09.673 [Executor task launch worker for task 5.0 in stage 10.0 (TID 29)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 372875555-447450666, partition values: [empty row]\n",
      "15:47:09.674 [Executor task launch worker for task 4.0 in stage 10.0 (TID 28)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 298300444-372875555, partition values: [empty row]\n",
      "15:47:09.674 [Executor task launch worker for task 3.0 in stage 10.0 (TID 27)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 223725333-298300444, partition values: [empty row]\n",
      "15:47:09.675 [Executor task launch worker for task 7.0 in stage 10.0 (TID 31)] INFO  org.apache.spark.executor.Executor - Running task 7.0 in stage 10.0 (TID 31)\n",
      "15:47:09.675 [Executor task launch worker for task 0.0 in stage 10.0 (TID 24)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 0-74575111, partition values: [empty row]\n",
      "15:47:09.682 [Executor task launch worker for task 2.0 in stage 10.0 (TID 26)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 149150222-223725333, partition values: [empty row]\n",
      "15:47:09.685 [Executor task launch worker for task 7.0 in stage 10.0 (TID 31)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 522025777-592406591, partition values: [empty row]\n",
      "15:47:09.691 [Executor task launch worker for task 6.0 in stage 10.0 (TID 30)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 447450666-522025777, partition values: [empty row]\n",
      "15:47:09.763 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_18_piece0 on 172.23.57.81:36925 in memory (size: 34.1 KiB, free: 434.0 MiB)\n",
      "15:47:09.770 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_16_piece0 on 172.23.57.81:36925 in memory (size: 34.0 KiB, free: 434.1 MiB)\n",
      "15:47:09.779 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_17_piece0 on 172.23.57.81:36925 in memory (size: 76.9 KiB, free: 434.1 MiB)\n",
      "15:47:09.931 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_13_piece0 on 172.23.57.81:36925 in memory (size: 78.2 KiB, free: 434.2 MiB)\n",
      "15:47:09.998 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_19_piece0 on 172.23.57.81:36925 in memory (size: 6.4 KiB, free: 434.2 MiB)\n",
      "15:47:10.027 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_14_piece0 on 172.23.57.81:36925 in memory (size: 34.0 KiB, free: 434.2 MiB)\n",
      "15:47:10.166 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_15_piece0 on 172.23.57.81:36925 in memory (size: 76.5 KiB, free: 434.3 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:47:16.870 [Executor task launch worker for task 7.0 in stage 10.0 (TID 31)] INFO  org.apache.spark.executor.Executor - Finished task 7.0 in stage 10.0 (TID 31). 1759 bytes result sent to driver\n",
      "15:47:16.873 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 10.0 (TID 31) in 7227 ms on 172.23.57.81 (executor driver) (1/8)\n",
      "15:47:17.035 [Executor task launch worker for task 2.0 in stage 10.0 (TID 26)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 10.0 (TID 26). 1759 bytes result sent to driver\n",
      "15:47:17.036 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 10.0 (TID 26) in 7392 ms on 172.23.57.81 (executor driver) (2/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:47:17.119 [Executor task launch worker for task 5.0 in stage 10.0 (TID 29)] INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 10.0 (TID 29). 1759 bytes result sent to driver\n",
      "15:47:17.122 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 10.0 (TID 29) in 7476 ms on 172.23.57.81 (executor driver) (3/8)\n",
      "15:47:17.138 [Executor task launch worker for task 0.0 in stage 10.0 (TID 24)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 24). 1759 bytes result sent to driver\n",
      "15:47:17.141 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 24) in 7497 ms on 172.23.57.81 (executor driver) (4/8)\n",
      "15:47:17.167 [Executor task launch worker for task 4.0 in stage 10.0 (TID 28)] INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 10.0 (TID 28). 1759 bytes result sent to driver\n",
      "15:47:17.168 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 10.0 (TID 28) in 7523 ms on 172.23.57.81 (executor driver) (5/8)\n",
      "15:47:17.231 [Executor task launch worker for task 6.0 in stage 10.0 (TID 30)] INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 10.0 (TID 30). 1759 bytes result sent to driver\n",
      "15:47:17.232 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 10.0 (TID 30) in 7586 ms on 172.23.57.81 (executor driver) (6/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:47:17.334 [Executor task launch worker for task 3.0 in stage 10.0 (TID 27)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 10.0 (TID 27). 1759 bytes result sent to driver\n",
      "15:47:17.335 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 10.0 (TID 27) in 7690 ms on 172.23.57.81 (executor driver) (7/8)\n",
      "15:47:17.345 [Executor task launch worker for task 1.0 in stage 10.0 (TID 25)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 10.0 (TID 25). 1759 bytes result sent to driver\n",
      "15:47:17.346 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 10.0 (TID 25) in 7702 ms on 172.23.57.81 (executor driver) (8/8)\n",
      "15:47:17.346 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "15:47:17.347 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 10 (csv at NativeMethodAccessorImpl.java:0) finished in 7.717 s\n",
      "15:47:17.347 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "15:47:17.347 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 10: Stage finished\n",
      "15:47:17.348 [Thread-3] INFO  org.apache.spark.scheduler.DAGScheduler - Job 10 finished: csv at NativeMethodAccessorImpl.java:0, took 7.725585 s\n",
      "15:47:17.372 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.InMemoryFileIndex - It took 1 ms to list leaf files for 1 paths.\n",
      "15:47:17.378 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.InMemoryFileIndex - It took 1 ms to list leaf files for 1 paths.\n",
      "15:47:17.444 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: \n",
      "15:47:17.445 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: (length(trim(value#290, None)) > 0)\n",
      "15:47:17.454 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_22 stored as values in memory (estimated size 199.0 KiB, free 433.7 MiB)\n",
      "15:47:17.462 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.7 MiB)\n",
      "15:47:17.463 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_22_piece0 in memory on 172.23.57.81:36925 (size: 34.1 KiB, free: 434.3 MiB)\n",
      "15:47:17.463 [Thread-3] INFO  org.apache.spark.SparkContext - Created broadcast 22 from csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:17.464 [Thread-3] INFO  org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "15:47:17.478 [Thread-3] INFO  org.apache.spark.SparkContext - Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:17.479 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 11 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "15:47:17.479 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (csv at NativeMethodAccessorImpl.java:0)\n",
      "15:47:17.479 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()\n",
      "15:47:17.483 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()\n",
      "15:47:17.484 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[52] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "15:47:17.486 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_23 stored as values in memory (estimated size 13.5 KiB, free 433.7 MiB)\n",
      "15:47:17.487 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.7 MiB)\n",
      "15:47:17.488 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_23_piece0 in memory on 172.23.57.81:36925 (size: 6.4 KiB, free: 434.3 MiB)\n",
      "15:47:17.489 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 23 from broadcast at DAGScheduler.scala:1585\n",
      "15:47:17.490 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[52] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "15:47:17.490 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0\n",
      "15:47:17.492 [dispatcher-event-loop-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 32) (172.23.57.81, executor driver, partition 0, PROCESS_LOCAL, 9620 bytes) \n",
      "15:47:17.492 [Executor task launch worker for task 0.0 in stage 11.0 (TID 32)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 32)\n",
      "15:47:17.495 [Executor task launch worker for task 0.0 in stage 11.0 (TID 32)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/airlines.csv, range: 0-359, partition values: [empty row]\n",
      "15:47:17.499 [Executor task launch worker for task 0.0 in stage 11.0 (TID 32)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 32). 1593 bytes result sent to driver\n",
      "15:47:17.500 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 32) in 9 ms on 172.23.57.81 (executor driver) (1/1)\n",
      "15:47:17.500 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "15:47:17.501 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 11 (csv at NativeMethodAccessorImpl.java:0) finished in 0.017 s\n",
      "15:47:17.501 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "15:47:17.501 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished\n",
      "15:47:17.502 [Thread-3] INFO  org.apache.spark.scheduler.DAGScheduler - Job 11 finished: csv at NativeMethodAccessorImpl.java:0, took 0.023615 s\n",
      "15:47:17.514 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: \n",
      "15:47:17.514 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: \n",
      "15:47:17.519 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_24 stored as values in memory (estimated size 199.0 KiB, free 433.5 MiB)\n",
      "15:47:17.527 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_24_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.4 MiB)\n",
      "15:47:17.527 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_24_piece0 in memory on 172.23.57.81:36925 (size: 34.1 KiB, free: 434.2 MiB)\n",
      "15:47:17.528 [Thread-3] INFO  org.apache.spark.SparkContext - Created broadcast 24 from csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:17.529 [Thread-3] INFO  org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "15:47:17.542 [Thread-3] INFO  org.apache.spark.SparkContext - Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:17.543 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 12 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "15:47:17.543 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 12 (csv at NativeMethodAccessorImpl.java:0)\n",
      "15:47:17.543 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()\n",
      "15:47:17.546 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()\n",
      "15:47:17.546 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[58] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "15:47:17.553 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_25 stored as values in memory (estimated size 26.9 KiB, free 433.4 MiB)\n",
      "15:47:17.555 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_25_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.4 MiB)\n",
      "15:47:17.556 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_25_piece0 in memory on 172.23.57.81:36925 (size: 12.7 KiB, free: 434.2 MiB)\n",
      "15:47:17.556 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 25 from broadcast at DAGScheduler.scala:1585\n",
      "15:47:17.557 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[58] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "15:47:17.557 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0\n",
      "15:47:17.558 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 12.0 (TID 33) (172.23.57.81, executor driver, partition 0, PROCESS_LOCAL, 9620 bytes) \n",
      "15:47:17.558 [Executor task launch worker for task 0.0 in stage 12.0 (TID 33)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 12.0 (TID 33)\n",
      "15:47:17.564 [Executor task launch worker for task 0.0 in stage 12.0 (TID 33)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/airlines.csv, range: 0-359, partition values: [empty row]\n",
      "15:47:17.570 [Executor task launch worker for task 0.0 in stage 12.0 (TID 33)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 12.0 (TID 33). 1517 bytes result sent to driver\n",
      "15:47:17.570 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 12.0 (TID 33) in 12 ms on 172.23.57.81 (executor driver) (1/1)\n",
      "15:47:17.571 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "15:47:17.571 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 12 (csv at NativeMethodAccessorImpl.java:0) finished in 0.024 s\n",
      "15:47:17.571 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "15:47:17.571 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished\n",
      "15:47:17.572 [Thread-3] INFO  org.apache.spark.scheduler.DAGScheduler - Job 12 finished: csv at NativeMethodAccessorImpl.java:0, took 0.029454 s\n",
      "15:47:17.590 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.InMemoryFileIndex - It took 1 ms to list leaf files for 1 paths.\n",
      "15:47:17.595 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.InMemoryFileIndex - It took 1 ms to list leaf files for 1 paths.\n",
      "15:47:17.632 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: \n",
      "15:47:17.632 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: (length(trim(value#311, None)) > 0)\n",
      "15:47:17.644 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_26 stored as values in memory (estimated size 199.0 KiB, free 433.2 MiB)\n",
      "15:47:17.651 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_26_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 433.2 MiB)\n",
      "15:47:17.652 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_26_piece0 in memory on 172.23.57.81:36925 (size: 34.1 KiB, free: 434.2 MiB)\n",
      "15:47:17.653 [Thread-3] INFO  org.apache.spark.SparkContext - Created broadcast 26 from csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:17.654 [Thread-3] INFO  org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "15:47:17.662 [Thread-3] INFO  org.apache.spark.SparkContext - Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:17.663 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 13 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "15:47:17.663 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 13 (csv at NativeMethodAccessorImpl.java:0)\n",
      "15:47:17.663 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()\n",
      "15:47:17.665 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()\n",
      "15:47:17.666 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 13 (MapPartitionsRDD[62] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "15:47:17.668 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_27 stored as values in memory (estimated size 13.5 KiB, free 433.2 MiB)\n",
      "15:47:17.670 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_27_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.1 MiB)\n",
      "15:47:17.670 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_27_piece0 in memory on 172.23.57.81:36925 (size: 6.4 KiB, free: 434.2 MiB)\n",
      "15:47:17.671 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 27 from broadcast at DAGScheduler.scala:1585\n",
      "15:47:17.672 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[62] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "15:47:17.672 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 13.0 with 1 tasks resource profile 0\n",
      "15:47:17.673 [dispatcher-event-loop-6] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 13.0 (TID 34) (172.23.57.81, executor driver, partition 0, PROCESS_LOCAL, 9620 bytes) \n",
      "15:47:17.674 [Executor task launch worker for task 0.0 in stage 13.0 (TID 34)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 13.0 (TID 34)\n",
      "15:47:17.678 [Executor task launch worker for task 0.0 in stage 13.0 (TID 34)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/airports.csv, range: 0-23867, partition values: [empty row]\n",
      "15:47:17.682 [Executor task launch worker for task 0.0 in stage 13.0 (TID 34)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 13.0 (TID 34). 1625 bytes result sent to driver\n",
      "15:47:17.683 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 13.0 (TID 34) in 10 ms on 172.23.57.81 (executor driver) (1/1)\n",
      "15:47:17.683 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "15:47:17.684 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 13 (csv at NativeMethodAccessorImpl.java:0) finished in 0.016 s\n",
      "15:47:17.684 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "15:47:17.684 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 13: Stage finished\n",
      "15:47:17.684 [Thread-3] INFO  org.apache.spark.scheduler.DAGScheduler - Job 13 finished: csv at NativeMethodAccessorImpl.java:0, took 0.021655 s\n",
      "15:47:17.696 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: \n",
      "15:47:17.696 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: \n",
      "15:47:17.700 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_28 stored as values in memory (estimated size 199.0 KiB, free 433.0 MiB)\n",
      "15:47:17.721 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_28_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 432.9 MiB)\n",
      "15:47:17.721 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_27_piece0 on 172.23.57.81:36925 in memory (size: 6.4 KiB, free: 434.2 MiB)\n",
      "15:47:17.722 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_28_piece0 in memory on 172.23.57.81:36925 (size: 34.1 KiB, free: 434.2 MiB)\n",
      "15:47:17.722 [Thread-3] INFO  org.apache.spark.SparkContext - Created broadcast 28 from csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:17.723 [Thread-3] INFO  org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "15:47:17.725 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_22_piece0 on 172.23.57.81:36925 in memory (size: 34.1 KiB, free: 434.2 MiB)\n",
      "15:47:17.729 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_25_piece0 on 172.23.57.81:36925 in memory (size: 12.7 KiB, free: 434.2 MiB)\n",
      "15:47:17.733 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_23_piece0 on 172.23.57.81:36925 in memory (size: 6.4 KiB, free: 434.2 MiB)\n",
      "15:47:17.737 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_24_piece0 on 172.23.57.81:36925 in memory (size: 34.1 KiB, free: 434.3 MiB)\n",
      "15:47:17.740 [Thread-3] INFO  org.apache.spark.SparkContext - Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "15:47:17.741 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 14 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "15:47:17.741 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 14 (csv at NativeMethodAccessorImpl.java:0)\n",
      "15:47:17.741 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()\n",
      "15:47:17.743 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()\n",
      "15:47:17.744 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[68] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "15:47:17.750 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_29 stored as values in memory (estimated size 26.9 KiB, free 433.4 MiB)\n",
      "15:47:17.752 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_29_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 433.4 MiB)\n",
      "15:47:17.752 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_29_piece0 in memory on 172.23.57.81:36925 (size: 12.8 KiB, free: 434.2 MiB)\n",
      "15:47:17.752 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 29 from broadcast at DAGScheduler.scala:1585\n",
      "15:47:17.753 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[68] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "15:47:17.753 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0\n",
      "15:47:17.754 [dispatcher-event-loop-7] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 14.0 (TID 35) (172.23.57.81, executor driver, partition 0, PROCESS_LOCAL, 9620 bytes) \n",
      "15:47:17.754 [Executor task launch worker for task 0.0 in stage 14.0 (TID 35)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 14.0 (TID 35)\n",
      "15:47:17.760 [Executor task launch worker for task 0.0 in stage 14.0 (TID 35)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/airports.csv, range: 0-23867, partition values: [empty row]\n",
      "15:47:17.767 [Executor task launch worker for task 0.0 in stage 14.0 (TID 35)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 14.0 (TID 35). 1592 bytes result sent to driver\n",
      "15:47:17.768 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 14.0 (TID 35) in 14 ms on 172.23.57.81 (executor driver) (1/1)\n",
      "15:47:17.768 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "15:47:17.768 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 14 (csv at NativeMethodAccessorImpl.java:0) finished in 0.023 s\n",
      "15:47:17.768 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "15:47:17.769 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished\n",
      "15:47:17.769 [Thread-3] INFO  org.apache.spark.scheduler.DAGScheduler - Job 14 finished: csv at NativeMethodAccessorImpl.java:0, took 0.029106 s\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    df_flights = spark.read.csv(path_vuelos, header= True, inferSchema=True)\n",
    "    df_airline = spark.read.csv(Path_aerolineas, header= True, inferSchema=True)\n",
    "    df_airports = spark.read.csv(path_aeropuertos, header=True, inferSchema=True)\n",
    "    \n",
    "except Exception as error:\n",
    "    logger.error(\"Error read.csv:\" + str(error))\n",
    "    errores_detectados.append(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "062baaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:47:17.823 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: \n",
      "15:47:17.823 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: \n",
      "15:47:17.868 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:17.870 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:17.870 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:17.870 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:17.870 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:17.871 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:17.871 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:17.888 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_30 stored as values in memory (estimated size 198.8 KiB, free 433.2 MiB)\n",
      "15:47:17.896 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_30_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.2 MiB)\n",
      "15:47:17.898 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_30_piece0 in memory on 172.23.57.81:36925 (size: 34.0 KiB, free: 434.2 MiB)\n",
      "15:47:17.898 [Thread-3] INFO  org.apache.spark.SparkContext - Created broadcast 30 from parquet at NativeMethodAccessorImpl.java:0\n",
      "15:47:17.900 [Thread-3] INFO  org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 74575111 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "15:47:17.906 [Thread-3] INFO  org.apache.spark.SparkContext - Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "15:47:17.908 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 15 (parquet at NativeMethodAccessorImpl.java:0) with 8 output partitions\n",
      "15:47:17.908 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 15 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "15:47:17.908 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()\n",
      "15:47:17.911 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()\n",
      "15:47:17.912 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 15 (MapPartitionsRDD[71] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "15:47:17.944 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_31 stored as values in memory (estimated size 218.2 KiB, free 433.0 MiB)\n",
      "15:47:17.946 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_31_piece0 stored as bytes in memory (estimated size 78.2 KiB, free 432.9 MiB)\n",
      "15:47:17.947 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_31_piece0 in memory on 172.23.57.81:36925 (size: 78.2 KiB, free: 434.1 MiB)\n",
      "15:47:17.947 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 31 from broadcast at DAGScheduler.scala:1585\n",
      "15:47:17.950 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 8 missing tasks from ResultStage 15 (MapPartitionsRDD[71] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))\n",
      "15:47:17.950 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 15.0 with 8 tasks resource profile 0\n",
      "15:47:17.952 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 15.0 (TID 36) (172.23.57.81, executor driver, partition 0, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:17.952 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 15.0 (TID 37) (172.23.57.81, executor driver, partition 1, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:17.952 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 15.0 (TID 38) (172.23.57.81, executor driver, partition 2, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:17.953 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 15.0 (TID 39) (172.23.57.81, executor driver, partition 3, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:17.953 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 15.0 (TID 40) (172.23.57.81, executor driver, partition 4, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:17.953 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 15.0 (TID 41) (172.23.57.81, executor driver, partition 5, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:17.953 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 15.0 (TID 42) (172.23.57.81, executor driver, partition 6, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:17.954 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 15.0 (TID 43) (172.23.57.81, executor driver, partition 7, PROCESS_LOCAL, 9619 bytes) \n",
      "15:47:17.954 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 15.0 (TID 36)\n",
      "15:47:17.954 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 15.0 (TID 38)\n",
      "15:47:17.954 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 15.0 (TID 37)\n",
      "15:47:17.954 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 15.0 (TID 40)\n",
      "15:47:17.954 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 15.0 (TID 39)\n",
      "15:47:17.954 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 15.0 (TID 41)\n",
      "15:47:17.955 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.spark.executor.Executor - Running task 7.0 in stage 15.0 (TID 43)\n",
      "15:47:17.957 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 15.0 (TID 42)\n",
      "15:47:17.981 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:17.981 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:17.981 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:17.981 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:17.981 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:17.982 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:17.982 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 447450666-522025777, partition values: [empty row]\n",
      "15:47:17.983 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:17.983 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:17.983 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:17.984 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:17.984 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:17.984 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:17.984 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 74575111-149150222, partition values: [empty row]\n",
      "15:47:17.990 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:17.990 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:17.991 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:17.991 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:17.991 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:17.992 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:17.992 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 298300444-372875555, partition values: [empty row]\n",
      "15:47:17.999 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:18.000 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:18.000 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:18.000 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:18.001 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:18.001 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:18.001 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 223725333-298300444, partition values: [empty row]\n",
      "15:47:18.002 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:18.002 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.002 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:18.003 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.003 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:18.003 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:18.003 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:18.004 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:18.004 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 372875555-447450666, partition values: [empty row]\n",
      "15:47:18.006 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.parquet.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "15:47:18.007 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.012 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"YEAR\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"MONTH\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY_OF_WEEK\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"FLIGHT_NUMBER\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAIL_NUMBER\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ORIGIN_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DESTINATION_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_DEPARTURE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_OUT\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_OFF\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ELAPSED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DISTANCE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_ON\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_IN\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_ARRIVAL\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DIVERTED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLATION_REASON\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_SYSTEM_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SECURITY_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"LATE_AIRCRAFT_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WEATHER_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 YEAR;\n",
      "  optional int32 MONTH;\n",
      "  optional int32 DAY;\n",
      "  optional int32 DAY_OF_WEEK;\n",
      "  optional binary AIRLINE (STRING);\n",
      "  optional int32 FLIGHT_NUMBER;\n",
      "  optional binary TAIL_NUMBER (STRING);\n",
      "  optional binary ORIGIN_AIRPORT (STRING);\n",
      "  optional binary DESTINATION_AIRPORT (STRING);\n",
      "  optional int32 SCHEDULED_DEPARTURE;\n",
      "  optional int32 DEPARTURE_TIME;\n",
      "  optional int32 DEPARTURE_DELAY;\n",
      "  optional int32 TAXI_OUT;\n",
      "  optional int32 WHEELS_OFF;\n",
      "  optional int32 SCHEDULED_TIME;\n",
      "  optional int32 ELAPSED_TIME;\n",
      "  optional int32 AIR_TIME;\n",
      "  optional int32 DISTANCE;\n",
      "  optional int32 WHEELS_ON;\n",
      "  optional int32 TAXI_IN;\n",
      "  optional int32 SCHEDULED_ARRIVAL;\n",
      "  optional int32 ARRIVAL_TIME;\n",
      "  optional int32 ARRIVAL_DELAY;\n",
      "  optional int32 DIVERTED;\n",
      "  optional int32 CANCELLED;\n",
      "  optional binary CANCELLATION_REASON (STRING);\n",
      "  optional int32 AIR_SYSTEM_DELAY;\n",
      "  optional int32 SECURITY_DELAY;\n",
      "  optional int32 AIRLINE_DELAY;\n",
      "  optional int32 LATE_AIRCRAFT_DELAY;\n",
      "  optional int32 WEATHER_DELAY;\n",
      "}\n",
      "\n",
      "       \n",
      "15:47:18.014 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:18.014 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:18.015 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:18.015 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:18.015 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:18.015 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:18.015 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 149150222-223725333, partition values: [empty row]\n",
      "15:47:18.018 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:18.019 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:18.019 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:18.019 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:18.019 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:18.019 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:18.020 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 522025777-592406591, partition values: [empty row]\n",
      "15:47:18.020 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:18.020 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:18.021 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.021 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:18.021 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.021 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:18.022 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:18.022 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:18.022 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.023 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.023 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.023 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.025 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.parquet.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "15:47:18.025 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.parquet.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "15:47:18.027 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.parquet.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "15:47:18.030 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"YEAR\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"MONTH\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY_OF_WEEK\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"FLIGHT_NUMBER\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAIL_NUMBER\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ORIGIN_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DESTINATION_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_DEPARTURE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_OUT\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_OFF\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ELAPSED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DISTANCE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_ON\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_IN\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_ARRIVAL\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DIVERTED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLATION_REASON\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_SYSTEM_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SECURITY_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"LATE_AIRCRAFT_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WEATHER_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 YEAR;\n",
      "  optional int32 MONTH;\n",
      "  optional int32 DAY;\n",
      "  optional int32 DAY_OF_WEEK;\n",
      "  optional binary AIRLINE (STRING);\n",
      "  optional int32 FLIGHT_NUMBER;\n",
      "  optional binary TAIL_NUMBER (STRING);\n",
      "  optional binary ORIGIN_AIRPORT (STRING);\n",
      "  optional binary DESTINATION_AIRPORT (STRING);\n",
      "  optional int32 SCHEDULED_DEPARTURE;\n",
      "  optional int32 DEPARTURE_TIME;\n",
      "  optional int32 DEPARTURE_DELAY;\n",
      "  optional int32 TAXI_OUT;\n",
      "  optional int32 WHEELS_OFF;\n",
      "  optional int32 SCHEDULED_TIME;\n",
      "  optional int32 ELAPSED_TIME;\n",
      "  optional int32 AIR_TIME;\n",
      "  optional int32 DISTANCE;\n",
      "  optional int32 WHEELS_ON;\n",
      "  optional int32 TAXI_IN;\n",
      "  optional int32 SCHEDULED_ARRIVAL;\n",
      "  optional int32 ARRIVAL_TIME;\n",
      "  optional int32 ARRIVAL_DELAY;\n",
      "  optional int32 DIVERTED;\n",
      "  optional int32 CANCELLED;\n",
      "  optional binary CANCELLATION_REASON (STRING);\n",
      "  optional int32 AIR_SYSTEM_DELAY;\n",
      "  optional int32 SECURITY_DELAY;\n",
      "  optional int32 AIRLINE_DELAY;\n",
      "  optional int32 LATE_AIRCRAFT_DELAY;\n",
      "  optional int32 WEATHER_DELAY;\n",
      "}\n",
      "\n",
      "       \n",
      "15:47:18.031 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"YEAR\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"MONTH\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY_OF_WEEK\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"FLIGHT_NUMBER\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAIL_NUMBER\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ORIGIN_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DESTINATION_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_DEPARTURE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_OUT\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_OFF\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ELAPSED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DISTANCE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_ON\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_IN\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_ARRIVAL\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DIVERTED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLATION_REASON\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_SYSTEM_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SECURITY_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"LATE_AIRCRAFT_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WEATHER_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 YEAR;\n",
      "  optional int32 MONTH;\n",
      "  optional int32 DAY;\n",
      "  optional int32 DAY_OF_WEEK;\n",
      "  optional binary AIRLINE (STRING);\n",
      "  optional int32 FLIGHT_NUMBER;\n",
      "  optional binary TAIL_NUMBER (STRING);\n",
      "  optional binary ORIGIN_AIRPORT (STRING);\n",
      "  optional binary DESTINATION_AIRPORT (STRING);\n",
      "  optional int32 SCHEDULED_DEPARTURE;\n",
      "  optional int32 DEPARTURE_TIME;\n",
      "  optional int32 DEPARTURE_DELAY;\n",
      "  optional int32 TAXI_OUT;\n",
      "  optional int32 WHEELS_OFF;\n",
      "  optional int32 SCHEDULED_TIME;\n",
      "  optional int32 ELAPSED_TIME;\n",
      "  optional int32 AIR_TIME;\n",
      "  optional int32 DISTANCE;\n",
      "  optional int32 WHEELS_ON;\n",
      "  optional int32 TAXI_IN;\n",
      "  optional int32 SCHEDULED_ARRIVAL;\n",
      "  optional int32 ARRIVAL_TIME;\n",
      "  optional int32 ARRIVAL_DELAY;\n",
      "  optional int32 DIVERTED;\n",
      "  optional int32 CANCELLED;\n",
      "  optional binary CANCELLATION_REASON (STRING);\n",
      "  optional int32 AIR_SYSTEM_DELAY;\n",
      "  optional int32 SECURITY_DELAY;\n",
      "  optional int32 AIRLINE_DELAY;\n",
      "  optional int32 LATE_AIRCRAFT_DELAY;\n",
      "  optional int32 WEATHER_DELAY;\n",
      "}\n",
      "\n",
      "       \n",
      "15:47:18.032 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.032 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.034 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.037 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"YEAR\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"MONTH\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY_OF_WEEK\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"FLIGHT_NUMBER\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAIL_NUMBER\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ORIGIN_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DESTINATION_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_DEPARTURE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_OUT\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_OFF\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ELAPSED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DISTANCE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_ON\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_IN\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_ARRIVAL\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DIVERTED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLATION_REASON\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_SYSTEM_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SECURITY_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"LATE_AIRCRAFT_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WEATHER_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 YEAR;\n",
      "  optional int32 MONTH;\n",
      "  optional int32 DAY;\n",
      "  optional int32 DAY_OF_WEEK;\n",
      "  optional binary AIRLINE (STRING);\n",
      "  optional int32 FLIGHT_NUMBER;\n",
      "  optional binary TAIL_NUMBER (STRING);\n",
      "  optional binary ORIGIN_AIRPORT (STRING);\n",
      "  optional binary DESTINATION_AIRPORT (STRING);\n",
      "  optional int32 SCHEDULED_DEPARTURE;\n",
      "  optional int32 DEPARTURE_TIME;\n",
      "  optional int32 DEPARTURE_DELAY;\n",
      "  optional int32 TAXI_OUT;\n",
      "  optional int32 WHEELS_OFF;\n",
      "  optional int32 SCHEDULED_TIME;\n",
      "  optional int32 ELAPSED_TIME;\n",
      "  optional int32 AIR_TIME;\n",
      "  optional int32 DISTANCE;\n",
      "  optional int32 WHEELS_ON;\n",
      "  optional int32 TAXI_IN;\n",
      "  optional int32 SCHEDULED_ARRIVAL;\n",
      "  optional int32 ARRIVAL_TIME;\n",
      "  optional int32 ARRIVAL_DELAY;\n",
      "  optional int32 DIVERTED;\n",
      "  optional int32 CANCELLED;\n",
      "  optional binary CANCELLATION_REASON (STRING);\n",
      "  optional int32 AIR_SYSTEM_DELAY;\n",
      "  optional int32 SECURITY_DELAY;\n",
      "  optional int32 AIRLINE_DELAY;\n",
      "  optional int32 LATE_AIRCRAFT_DELAY;\n",
      "  optional int32 WEATHER_DELAY;\n",
      "}\n",
      "\n",
      "       \n",
      "15:47:18.043 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.parquet.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "15:47:18.036 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.043 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.045 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"YEAR\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"MONTH\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY_OF_WEEK\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"FLIGHT_NUMBER\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAIL_NUMBER\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ORIGIN_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DESTINATION_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_DEPARTURE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_OUT\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_OFF\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ELAPSED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DISTANCE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_ON\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_IN\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_ARRIVAL\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DIVERTED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLATION_REASON\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_SYSTEM_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SECURITY_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"LATE_AIRCRAFT_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WEATHER_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 YEAR;\n",
      "  optional int32 MONTH;\n",
      "  optional int32 DAY;\n",
      "  optional int32 DAY_OF_WEEK;\n",
      "  optional binary AIRLINE (STRING);\n",
      "  optional int32 FLIGHT_NUMBER;\n",
      "  optional binary TAIL_NUMBER (STRING);\n",
      "  optional binary ORIGIN_AIRPORT (STRING);\n",
      "  optional binary DESTINATION_AIRPORT (STRING);\n",
      "  optional int32 SCHEDULED_DEPARTURE;\n",
      "  optional int32 DEPARTURE_TIME;\n",
      "  optional int32 DEPARTURE_DELAY;\n",
      "  optional int32 TAXI_OUT;\n",
      "  optional int32 WHEELS_OFF;\n",
      "  optional int32 SCHEDULED_TIME;\n",
      "  optional int32 ELAPSED_TIME;\n",
      "  optional int32 AIR_TIME;\n",
      "  optional int32 DISTANCE;\n",
      "  optional int32 WHEELS_ON;\n",
      "  optional int32 TAXI_IN;\n",
      "  optional int32 SCHEDULED_ARRIVAL;\n",
      "  optional int32 ARRIVAL_TIME;\n",
      "  optional int32 ARRIVAL_DELAY;\n",
      "  optional int32 DIVERTED;\n",
      "  optional int32 CANCELLED;\n",
      "  optional binary CANCELLATION_REASON (STRING);\n",
      "  optional int32 AIR_SYSTEM_DELAY;\n",
      "  optional int32 SECURITY_DELAY;\n",
      "  optional int32 AIRLINE_DELAY;\n",
      "  optional int32 LATE_AIRCRAFT_DELAY;\n",
      "  optional int32 WEATHER_DELAY;\n",
      "}\n",
      "\n",
      "       \n",
      "15:47:18.047 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.parquet.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "15:47:18.047 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.parquet.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "15:47:18.049 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.049 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"YEAR\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"MONTH\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY_OF_WEEK\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"FLIGHT_NUMBER\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAIL_NUMBER\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ORIGIN_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DESTINATION_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_DEPARTURE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_OUT\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_OFF\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ELAPSED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DISTANCE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_ON\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_IN\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_ARRIVAL\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DIVERTED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLATION_REASON\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_SYSTEM_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SECURITY_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"LATE_AIRCRAFT_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WEATHER_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 YEAR;\n",
      "  optional int32 MONTH;\n",
      "  optional int32 DAY;\n",
      "  optional int32 DAY_OF_WEEK;\n",
      "  optional binary AIRLINE (STRING);\n",
      "  optional int32 FLIGHT_NUMBER;\n",
      "  optional binary TAIL_NUMBER (STRING);\n",
      "  optional binary ORIGIN_AIRPORT (STRING);\n",
      "  optional binary DESTINATION_AIRPORT (STRING);\n",
      "  optional int32 SCHEDULED_DEPARTURE;\n",
      "  optional int32 DEPARTURE_TIME;\n",
      "  optional int32 DEPARTURE_DELAY;\n",
      "  optional int32 TAXI_OUT;\n",
      "  optional int32 WHEELS_OFF;\n",
      "  optional int32 SCHEDULED_TIME;\n",
      "  optional int32 ELAPSED_TIME;\n",
      "  optional int32 AIR_TIME;\n",
      "  optional int32 DISTANCE;\n",
      "  optional int32 WHEELS_ON;\n",
      "  optional int32 TAXI_IN;\n",
      "  optional int32 SCHEDULED_ARRIVAL;\n",
      "  optional int32 ARRIVAL_TIME;\n",
      "  optional int32 ARRIVAL_DELAY;\n",
      "  optional int32 DIVERTED;\n",
      "  optional int32 CANCELLED;\n",
      "  optional binary CANCELLATION_REASON (STRING);\n",
      "  optional int32 AIR_SYSTEM_DELAY;\n",
      "  optional int32 SECURITY_DELAY;\n",
      "  optional int32 AIRLINE_DELAY;\n",
      "  optional int32 LATE_AIRCRAFT_DELAY;\n",
      "  optional int32 WEATHER_DELAY;\n",
      "}\n",
      "\n",
      "       \n",
      "15:47:18.049 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:18.049 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"YEAR\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"MONTH\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY_OF_WEEK\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"FLIGHT_NUMBER\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAIL_NUMBER\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ORIGIN_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DESTINATION_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_DEPARTURE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_OUT\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_OFF\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ELAPSED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DISTANCE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_ON\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_IN\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_ARRIVAL\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DIVERTED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLATION_REASON\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_SYSTEM_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SECURITY_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"LATE_AIRCRAFT_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WEATHER_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 YEAR;\n",
      "  optional int32 MONTH;\n",
      "  optional int32 DAY;\n",
      "  optional int32 DAY_OF_WEEK;\n",
      "  optional binary AIRLINE (STRING);\n",
      "  optional int32 FLIGHT_NUMBER;\n",
      "  optional binary TAIL_NUMBER (STRING);\n",
      "  optional binary ORIGIN_AIRPORT (STRING);\n",
      "  optional binary DESTINATION_AIRPORT (STRING);\n",
      "  optional int32 SCHEDULED_DEPARTURE;\n",
      "  optional int32 DEPARTURE_TIME;\n",
      "  optional int32 DEPARTURE_DELAY;\n",
      "  optional int32 TAXI_OUT;\n",
      "  optional int32 WHEELS_OFF;\n",
      "  optional int32 SCHEDULED_TIME;\n",
      "  optional int32 ELAPSED_TIME;\n",
      "  optional int32 AIR_TIME;\n",
      "  optional int32 DISTANCE;\n",
      "  optional int32 WHEELS_ON;\n",
      "  optional int32 TAXI_IN;\n",
      "  optional int32 SCHEDULED_ARRIVAL;\n",
      "  optional int32 ARRIVAL_TIME;\n",
      "  optional int32 ARRIVAL_DELAY;\n",
      "  optional int32 DIVERTED;\n",
      "  optional int32 CANCELLED;\n",
      "  optional binary CANCELLATION_REASON (STRING);\n",
      "  optional int32 AIR_SYSTEM_DELAY;\n",
      "  optional int32 SECURITY_DELAY;\n",
      "  optional int32 AIRLINE_DELAY;\n",
      "  optional int32 LATE_AIRCRAFT_DELAY;\n",
      "  optional int32 WEATHER_DELAY;\n",
      "}\n",
      "\n",
      "       \n",
      "15:47:18.051 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.parquet.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "15:47:18.053 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"YEAR\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"MONTH\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DAY_OF_WEEK\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"FLIGHT_NUMBER\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAIL_NUMBER\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ORIGIN_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DESTINATION_AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_DEPARTURE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DEPARTURE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_OUT\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_OFF\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ELAPSED_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DISTANCE\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WHEELS_ON\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"TAXI_IN\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SCHEDULED_ARRIVAL\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_TIME\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ARRIVAL_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"DIVERTED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLED\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CANCELLATION_REASON\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIR_SYSTEM_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"SECURITY_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"LATE_AIRCRAFT_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"WEATHER_DELAY\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 YEAR;\n",
      "  optional int32 MONTH;\n",
      "  optional int32 DAY;\n",
      "  optional int32 DAY_OF_WEEK;\n",
      "  optional binary AIRLINE (STRING);\n",
      "  optional int32 FLIGHT_NUMBER;\n",
      "  optional binary TAIL_NUMBER (STRING);\n",
      "  optional binary ORIGIN_AIRPORT (STRING);\n",
      "  optional binary DESTINATION_AIRPORT (STRING);\n",
      "  optional int32 SCHEDULED_DEPARTURE;\n",
      "  optional int32 DEPARTURE_TIME;\n",
      "  optional int32 DEPARTURE_DELAY;\n",
      "  optional int32 TAXI_OUT;\n",
      "  optional int32 WHEELS_OFF;\n",
      "  optional int32 SCHEDULED_TIME;\n",
      "  optional int32 ELAPSED_TIME;\n",
      "  optional int32 AIR_TIME;\n",
      "  optional int32 DISTANCE;\n",
      "  optional int32 WHEELS_ON;\n",
      "  optional int32 TAXI_IN;\n",
      "  optional int32 SCHEDULED_ARRIVAL;\n",
      "  optional int32 ARRIVAL_TIME;\n",
      "  optional int32 ARRIVAL_DELAY;\n",
      "  optional int32 DIVERTED;\n",
      "  optional int32 CANCELLED;\n",
      "  optional binary CANCELLATION_REASON (STRING);\n",
      "  optional int32 AIR_SYSTEM_DELAY;\n",
      "  optional int32 SECURITY_DELAY;\n",
      "  optional int32 AIRLINE_DELAY;\n",
      "  optional int32 LATE_AIRCRAFT_DELAY;\n",
      "  optional int32 WEATHER_DELAY;\n",
      "}\n",
      "\n",
      "       \n",
      "15:47:18.140 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/flights.csv, range: 0-74575111, partition values: [empty row]\n",
      "15:47:18.201 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] WARN  org.apache.parquet.hadoop.MemoryManager - Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:47:18.737 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_26_piece0 on 172.23.57.81:36925 in memory (size: 34.1 KiB, free: 434.2 MiB)\n",
      "15:47:18.828 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_28_piece0 on 172.23.57.81:36925 in memory (size: 34.1 KiB, free: 434.2 MiB)\n",
      "15:47:18.901 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_29_piece0 on 172.23.57.81:36925 in memory (size: 12.8 KiB, free: 434.2 MiB)\n",
      "15:47:29.725 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_202505291547173732148328895415281_0015_m_000007_43' to file:/home/illidan/proyecto_desde0/archivos_parquet/df_flights/_temporary/0/task_202505291547173732148328895415281_0015_m_000007\n",
      "15:47:29.725 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_202505291547173732148328895415281_0015_m_000007_43: Committed. Elapsed time: 1 ms.\n",
      "15:47:29.728 [Executor task launch worker for task 7.0 in stage 15.0 (TID 43)] INFO  org.apache.spark.executor.Executor - Finished task 7.0 in stage 15.0 (TID 43). 2502 bytes result sent to driver\n",
      "15:47:29.729 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 15.0 (TID 43) in 11775 ms on 172.23.57.81 (executor driver) (1/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:47:30.357 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_202505291547173732148328895415281_0015_m_000006_42' to file:/home/illidan/proyecto_desde0/archivos_parquet/df_flights/_temporary/0/task_202505291547173732148328895415281_0015_m_000006\n",
      "15:47:30.367 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_202505291547173732148328895415281_0015_m_000006_42: Committed. Elapsed time: 10 ms.\n",
      "15:47:30.376 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_202505291547173732148328895415281_0015_m_000002_38' to file:/home/illidan/proyecto_desde0/archivos_parquet/df_flights/_temporary/0/task_202505291547173732148328895415281_0015_m_000002\n",
      "15:47:30.376 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_202505291547173732148328895415281_0015_m_000002_38: Committed. Elapsed time: 0 ms.\n",
      "15:47:30.376 [Executor task launch worker for task 6.0 in stage 15.0 (TID 42)] INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 15.0 (TID 42). 2502 bytes result sent to driver\n",
      "15:47:30.379 [Executor task launch worker for task 2.0 in stage 15.0 (TID 38)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 15.0 (TID 38). 2502 bytes result sent to driver\n",
      "15:47:30.380 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 15.0 (TID 38) in 12428 ms on 172.23.57.81 (executor driver) (2/8)\n",
      "15:47:30.381 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 15.0 (TID 42) in 12428 ms on 172.23.57.81 (executor driver) (3/8)\n",
      "15:47:30.487 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_202505291547173732148328895415281_0015_m_000005_41' to file:/home/illidan/proyecto_desde0/archivos_parquet/df_flights/_temporary/0/task_202505291547173732148328895415281_0015_m_000005\n",
      "15:47:30.487 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_202505291547173732148328895415281_0015_m_000005_41: Committed. Elapsed time: 0 ms.\n",
      "15:47:30.489 [Executor task launch worker for task 5.0 in stage 15.0 (TID 41)] INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 15.0 (TID 41). 2502 bytes result sent to driver\n",
      "15:47:30.490 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 15.0 (TID 41) in 12537 ms on 172.23.57.81 (executor driver) (4/8)\n",
      "15:47:30.535 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_202505291547173732148328895415281_0015_m_000001_37' to file:/home/illidan/proyecto_desde0/archivos_parquet/df_flights/_temporary/0/task_202505291547173732148328895415281_0015_m_000001\n",
      "15:47:30.536 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_202505291547173732148328895415281_0015_m_000001_37: Committed. Elapsed time: 0 ms.\n",
      "15:47:30.537 [Executor task launch worker for task 1.0 in stage 15.0 (TID 37)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 15.0 (TID 37). 2502 bytes result sent to driver\n",
      "15:47:30.538 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 15.0 (TID 37) in 12586 ms on 172.23.57.81 (executor driver) (5/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:47:30.579 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_202505291547173732148328895415281_0015_m_000000_36' to file:/home/illidan/proyecto_desde0/archivos_parquet/df_flights/_temporary/0/task_202505291547173732148328895415281_0015_m_000000\n",
      "15:47:30.579 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_202505291547173732148328895415281_0015_m_000000_36: Committed. Elapsed time: 0 ms.\n",
      "15:47:30.581 [Executor task launch worker for task 0.0 in stage 15.0 (TID 36)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 15.0 (TID 36). 2502 bytes result sent to driver\n",
      "15:47:30.583 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 15.0 (TID 36) in 12631 ms on 172.23.57.81 (executor driver) (6/8)\n",
      "15:47:30.706 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_202505291547173732148328895415281_0015_m_000003_39' to file:/home/illidan/proyecto_desde0/archivos_parquet/df_flights/_temporary/0/task_202505291547173732148328895415281_0015_m_000003\n",
      "15:47:30.706 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_202505291547173732148328895415281_0015_m_000003_39: Committed. Elapsed time: 0 ms.\n",
      "15:47:30.708 [Executor task launch worker for task 3.0 in stage 15.0 (TID 39)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 15.0 (TID 39). 2502 bytes result sent to driver\n",
      "15:47:30.711 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 15.0 (TID 39) in 12758 ms on 172.23.57.81 (executor driver) (7/8)\n",
      "15:47:30.775 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_202505291547173732148328895415281_0015_m_000004_40' to file:/home/illidan/proyecto_desde0/archivos_parquet/df_flights/_temporary/0/task_202505291547173732148328895415281_0015_m_000004\n",
      "15:47:30.775 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_202505291547173732148328895415281_0015_m_000004_40: Committed. Elapsed time: 0 ms.\n",
      "15:47:30.776 [Executor task launch worker for task 4.0 in stage 15.0 (TID 40)] INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 15.0 (TID 40). 2502 bytes result sent to driver\n",
      "15:47:30.777 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 15.0 (TID 40) in 12824 ms on 172.23.57.81 (executor driver) (8/8)\n",
      "15:47:30.777 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "15:47:30.777 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 15 (parquet at NativeMethodAccessorImpl.java:0) finished in 12.863 s\n",
      "15:47:30.777 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "15:47:30.777 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 15: Stage finished\n",
      "15:47:30.778 [Thread-3] INFO  org.apache.spark.scheduler.DAGScheduler - Job 15 finished: parquet at NativeMethodAccessorImpl.java:0, took 9.952985 s\n",
      "15:47:30.778 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileFormatWriter - Start to commit write Job 6c18eb2c-c753-4a23-b67e-11756e024904.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:47:30.793 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileFormatWriter - Write Job 6c18eb2c-c753-4a23-b67e-11756e024904 committed. Elapsed time: 15 ms.\n",
      "15:47:30.794 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileFormatWriter - Finished processing stats for write job 6c18eb2c-c753-4a23-b67e-11756e024904.\n",
      "15:47:30.811 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: \n",
      "15:47:30.811 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: \n",
      "15:47:30.816 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:30.816 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:30.817 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:30.817 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:30.817 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:30.817 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:30.817 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:30.843 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_32 stored as values in memory (estimated size 198.8 KiB, free 433.2 MiB)\n",
      "15:47:30.866 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_32_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.2 MiB)\n",
      "15:47:30.867 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_32_piece0 in memory on 172.23.57.81:36925 (size: 34.0 KiB, free: 434.2 MiB)\n",
      "15:47:30.868 [Thread-3] INFO  org.apache.spark.SparkContext - Created broadcast 32 from parquet at NativeMethodAccessorImpl.java:0\n",
      "15:47:30.869 [Thread-3] INFO  org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "15:47:30.875 [Thread-3] INFO  org.apache.spark.SparkContext - Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "15:47:30.876 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 16 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "15:47:30.876 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 16 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "15:47:30.876 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()\n",
      "15:47:30.876 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()\n",
      "15:47:30.878 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 16 (MapPartitionsRDD[74] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "15:47:30.900 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_33 stored as values in memory (estimated size 211.1 KiB, free 433.0 MiB)\n",
      "15:47:30.902 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_33_piece0 stored as bytes in memory (estimated size 76.5 KiB, free 432.9 MiB)\n",
      "15:47:30.903 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_33_piece0 in memory on 172.23.57.81:36925 (size: 76.5 KiB, free: 434.1 MiB)\n",
      "15:47:30.924 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 33 from broadcast at DAGScheduler.scala:1585\n",
      "15:47:30.925 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[74] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "15:47:30.925 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_21_piece0 on 172.23.57.81:36925 in memory (size: 13.0 KiB, free: 434.1 MiB)\n",
      "15:47:30.925 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 16.0 with 1 tasks resource profile 0\n",
      "15:47:30.926 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 16.0 (TID 44) (172.23.57.81, executor driver, partition 0, PROCESS_LOCAL, 9620 bytes) \n",
      "15:47:30.927 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 16.0 (TID 44)\n",
      "15:47:30.935 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_12_piece0 on 172.23.57.81:36925 in memory (size: 34.0 KiB, free: 434.1 MiB)\n",
      "15:47:30.940 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_31_piece0 on 172.23.57.81:36925 in memory (size: 78.2 KiB, free: 434.2 MiB)\n",
      "15:47:30.942 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:30.942 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:30.942 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:30.942 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:30.942 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:30.942 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:30.942 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:30.943 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:30.945 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_20_piece0 on 172.23.57.81:36925 in memory (size: 34.1 KiB, free: 434.3 MiB)\n",
      "15:47:30.946 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.parquet.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "15:47:30.947 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"IATA_CODE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRLINE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary IATA_CODE (STRING);\n",
      "  optional binary AIRLINE (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "15:47:30.973 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/airlines.csv, range: 0-359, partition values: [empty row]\n",
      "15:47:30.979 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_202505291547305577398507956553887_0016_m_000000_44' to file:/home/illidan/proyecto_desde0/archivos_parquet/df_airline/_temporary/0/task_202505291547305577398507956553887_0016_m_000000\n",
      "15:47:30.979 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_202505291547305577398507956553887_0016_m_000000_44: Committed. Elapsed time: 0 ms.\n",
      "15:47:30.980 [Executor task launch worker for task 0.0 in stage 16.0 (TID 44)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 16.0 (TID 44). 2459 bytes result sent to driver\n",
      "15:47:30.981 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 16.0 (TID 44) in 55 ms on 172.23.57.81 (executor driver) (1/1)\n",
      "15:47:30.981 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 16.0, whose tasks have all completed, from pool \n",
      "15:47:30.982 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 16 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.104 s\n",
      "15:47:30.982 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "15:47:30.982 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 16: Stage finished\n",
      "15:47:30.982 [Thread-3] INFO  org.apache.spark.scheduler.DAGScheduler - Job 16 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.107172 s\n",
      "15:47:30.983 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileFormatWriter - Start to commit write Job 7d2f75c6-42dc-4ba0-b134-1e86d4ae3639.\n",
      "15:47:30.995 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileFormatWriter - Write Job 7d2f75c6-42dc-4ba0-b134-1e86d4ae3639 committed. Elapsed time: 12 ms.\n",
      "15:47:30.995 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileFormatWriter - Finished processing stats for write job 7d2f75c6-42dc-4ba0-b134-1e86d4ae3639.\n",
      "15:47:31.016 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: \n",
      "15:47:31.016 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: \n",
      "15:47:31.022 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:31.024 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:31.024 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:31.024 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:31.024 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:31.024 [Thread-3] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:31.024 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:31.055 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_34 stored as values in memory (estimated size 198.8 KiB, free 433.5 MiB)\n",
      "15:47:31.063 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_34_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.4 MiB)\n",
      "15:47:31.064 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_34_piece0 in memory on 172.23.57.81:36925 (size: 34.0 KiB, free: 434.2 MiB)\n",
      "15:47:31.064 [Thread-3] INFO  org.apache.spark.SparkContext - Created broadcast 34 from parquet at NativeMethodAccessorImpl.java:0\n",
      "15:47:31.065 [Thread-3] INFO  org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "15:47:31.069 [Thread-3] INFO  org.apache.spark.SparkContext - Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "15:47:31.070 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 17 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "15:47:31.070 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 17 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "15:47:31.071 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()\n",
      "15:47:31.071 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()\n",
      "15:47:31.072 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 17 (MapPartitionsRDD[77] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "15:47:31.094 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_35 stored as values in memory (estimated size 212.2 KiB, free 433.2 MiB)\n",
      "15:47:31.097 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_35_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 433.2 MiB)\n",
      "15:47:31.098 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_35_piece0 in memory on 172.23.57.81:36925 (size: 76.9 KiB, free: 434.2 MiB)\n",
      "15:47:31.098 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 35 from broadcast at DAGScheduler.scala:1585\n",
      "15:47:31.099 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[77] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "15:47:31.099 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 17.0 with 1 tasks resource profile 0\n",
      "15:47:31.100 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 17.0 (TID 45) (172.23.57.81, executor driver, partition 0, PROCESS_LOCAL, 9620 bytes) \n",
      "15:47:31.106 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 17.0 (TID 45)\n",
      "15:47:31.125 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:31.126 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:31.126 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:31.127 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "15:47:31.127 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "15:47:31.127 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "15:47:31.127 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:31.128 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY\n",
      "15:47:31.129 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.parquet.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "15:47:31.130 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"IATA_CODE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"AIRPORT\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"CITY\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"STATE\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"COUNTRY\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"LATITUDE\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"LONGITUDE\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary IATA_CODE (STRING);\n",
      "  optional binary AIRPORT (STRING);\n",
      "  optional binary CITY (STRING);\n",
      "  optional binary STATE (STRING);\n",
      "  optional binary COUNTRY (STRING);\n",
      "  optional double LATITUDE;\n",
      "  optional double LONGITUDE;\n",
      "}\n",
      "\n",
      "       \n",
      "15:47:31.155 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///home/illidan/proyecto_desde0/archivos/airports.csv, range: 0-23867, partition values: [empty row]\n",
      "15:47:31.181 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_202505291547312951373831667097317_0017_m_000000_45' to file:/home/illidan/proyecto_desde0/archivos_parquet/df_airports/_temporary/0/task_202505291547312951373831667097317_0017_m_000000\n",
      "15:47:31.182 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.spark.mapred.SparkHadoopMapRedUtil - attempt_202505291547312951373831667097317_0017_m_000000_45: Committed. Elapsed time: 1 ms.\n",
      "15:47:31.184 [Executor task launch worker for task 0.0 in stage 17.0 (TID 45)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 17.0 (TID 45). 2459 bytes result sent to driver\n",
      "15:47:31.185 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 17.0 (TID 45) in 85 ms on 172.23.57.81 (executor driver) (1/1)\n",
      "15:47:31.185 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "15:47:31.186 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 17 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.114 s\n",
      "15:47:31.186 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 17 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "15:47:31.187 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 17: Stage finished\n",
      "15:47:31.187 [Thread-3] INFO  org.apache.spark.scheduler.DAGScheduler - Job 17 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.117276 s\n",
      "15:47:31.187 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileFormatWriter - Start to commit write Job 3345fb86-d530-4568-9559-66fda5ad2c13.\n",
      "15:47:31.200 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileFormatWriter - Write Job 3345fb86-d530-4568-9559-66fda5ad2c13 committed. Elapsed time: 12 ms.\n",
      "15:47:31.200 [Thread-3] INFO  org.apache.spark.sql.execution.datasources.FileFormatWriter - Finished processing stats for write job 3345fb86-d530-4568-9559-66fda5ad2c13.\n"
     ]
    }
   ],
   "source": [
    "#Export into a parquet file\n",
    "\n",
    "try:\n",
    "    df_flights.write.parquet(path_df_flights, mode=\"overwrite\")\n",
    "    df_airline.write.parquet(path_df_airline, mode=\"overwrite\")\n",
    "    df_airports.write.parquet(path_df_airports, mode=\"overwrite\")\n",
    "except Exception as error:\n",
    "    logger.error(\"Error write.parquet:\" + str(error))\n",
    "    errores_detectados.append(str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
